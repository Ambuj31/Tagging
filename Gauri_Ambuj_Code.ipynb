{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/Tag_dataset_tags.csv')\n",
        "\n",
        "# Data Cleaning\n",
        "df.dropna(subset=['Description'], inplace=True)  # Drop rows with missing descriptions\n",
        "df.drop_duplicates(subset=['Description'], keep='first', inplace=True)  # Remove duplicates\n",
        "\n",
        "# Text Preprocessing with Lemmatization and Stopword Removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "df['lemmatized_description'] = df['Description'].apply(lemmatize_text)\n",
        "\n",
        "# Remove Stopwords from Lemmatized Text\n",
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "df['cleaned_lemmatized_description'] = df['lemmatized_description'].apply(remove_stopwords)\n",
        "\n",
        "# Create Array of Words from Cleaned Lemmatized Description\n",
        "def create_word_array(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "df['word_array'] = df['cleaned_lemmatized_description'].apply(create_word_array)\n",
        "\n",
        "# Perform POS Tagging on Each Word in Each Array\n",
        "def pos_tag_words(word_array):\n",
        "    return pos_tag(word_array)\n",
        "\n",
        "df['pos_tagged_words'] = df['word_array'].apply(pos_tag_words)\n",
        "\n",
        "# Create Separate Columns for Specific POS Tags\n",
        "def extract_pos_tags(tagged_words, pos_tag):\n",
        "    return ' '.join([word for word, tag in tagged_words if tag == pos_tag])\n",
        "\n",
        "df['Nouns'] = df['pos_tagged_words'].apply(lambda x: extract_pos_tags(x, 'NN') + ' ' + extract_pos_tags(x, 'NNS') + ' ' + extract_pos_tags(x, 'NNP') + ' ' + extract_pos_tags(x, 'NNPS'))\n",
        "df['Verbs'] = df['pos_tagged_words'].apply(lambda x: extract_pos_tags(x, 'VB') + ' ' + extract_pos_tags(x, 'VBD') + ' ' + extract_pos_tags(x, 'VBG') + ' ' + extract_pos_tags(x, 'VBN') + ' ' + extract_pos_tags(x, 'VBP') + ' ' + extract_pos_tags(x, 'VBZ'))\n",
        "df['Adjectives'] = df['pos_tagged_words'].apply(lambda x: extract_pos_tags(x, 'JJ'))\n",
        "# Save the preprocessed data with specific POS tagged words to a new CSV file\n",
        "df.to_csv('Final_pd.csv', index=False)"
      ],
      "metadata": {
        "id": "EkWRPyUeTEtT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d19352b-c52a-4f94-b2b6-ab588441e118"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "RvqNKMpjTZle"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "HZ8UGwjqTaSJ",
        "outputId": "42d396ce-57ad-4840-c6c4-0061ef05f7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID   Name                                        Description  \\\n",
              "0  1.0  Sarah  Sarah is a dedicated student with a passion fo...   \n",
              "1  2.0   Alex  Alex is a tech enthusiast studying Computer Sc...   \n",
              "2  3.0  Emily  Emily is an avid reader and historian, focusin...   \n",
              "3  4.0  James  James is a science enthusiast excelling in Bio...   \n",
              "4  5.0    Mia  Mia is a student of Economics and Political Sc...   \n",
              "\n",
              "               Tags                             lemmatized_description  \\\n",
              "0           Physics  Sarah is a dedicated student with a passion fo...   \n",
              "1  Computer Science  Alex is a tech enthusiast studying Computer Sc...   \n",
              "2        Literature  Emily is an avid reader and historian , focusi...   \n",
              "3         Chemistry  James is a science enthusiast excelling in Bio...   \n",
              "4         Economics  Mia is a student of Economics and Political Sc...   \n",
              "\n",
              "                      cleaned_lemmatized_description  \\\n",
              "0  Sarah dedicated student passion Mathematics Ph...   \n",
              "1  Alex tech enthusiast studying Computer Science...   \n",
              "2  Emily avid reader historian , focusing Literat...   \n",
              "3  James science enthusiast excelling Biology Che...   \n",
              "4  Mia student Economics Political Science , pass...   \n",
              "\n",
              "                                          word_array  \\\n",
              "0  [Sarah, dedicated, student, passion, Mathemati...   \n",
              "1  [Alex, tech, enthusiast, studying, Computer, S...   \n",
              "2  [Emily, avid, reader, historian, ,, focusing, ...   \n",
              "3  [James, science, enthusiast, excelling, Biolog...   \n",
              "4  [Mia, student, Economics, Political, Science, ...   \n",
              "\n",
              "                                    pos_tagged_words  \\\n",
              "0  [(Sarah, NNP), (dedicated, VBD), (student, NN)...   \n",
              "1  [(Alex, NNP), (tech, VBD), (enthusiast, RB), (...   \n",
              "2  [(Emily, RB), (avid, JJ), (reader, NN), (histo...   \n",
              "3  [(James, NNP), (science, NN), (enthusiast, NN)...   \n",
              "4  [(Mia, NNP), (student, NN), (Economics, NNP), ...   \n",
              "\n",
              "                                               Nouns  \\\n",
              "0  student passion interest lie realm fervor curi...   \n",
              "1  interest revolve technology computing  Alex Co...   \n",
              "2  reader historian inspiration endeavor  Literat...   \n",
              "3  science enthusiast interest research experimen...   \n",
              "4  student passionate understanding interest comm...   \n",
              "\n",
              "                               Verbs                        Adjectives  \n",
              "0               dedicated   mystery                           universe  \n",
              "1   tech studying shaping   explores               cutting-edge future  \n",
              "2          find  focusing drawing     avid joy deep narrative creative  \n",
              "3             excelling  drive seek                  unravel molecular  \n",
              "4           making informed reflect            global dynamic positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf367ef1-1749-439a-8dc7-68d71da7d56c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>Tags</th>\n",
              "      <th>lemmatized_description</th>\n",
              "      <th>cleaned_lemmatized_description</th>\n",
              "      <th>word_array</th>\n",
              "      <th>pos_tagged_words</th>\n",
              "      <th>Nouns</th>\n",
              "      <th>Verbs</th>\n",
              "      <th>Adjectives</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Sarah</td>\n",
              "      <td>Sarah is a dedicated student with a passion fo...</td>\n",
              "      <td>Physics</td>\n",
              "      <td>Sarah is a dedicated student with a passion fo...</td>\n",
              "      <td>Sarah dedicated student passion Mathematics Ph...</td>\n",
              "      <td>[Sarah, dedicated, student, passion, Mathemati...</td>\n",
              "      <td>[(Sarah, NNP), (dedicated, VBD), (student, NN)...</td>\n",
              "      <td>student passion interest lie realm fervor curi...</td>\n",
              "      <td>dedicated   mystery</td>\n",
              "      <td>universe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Alex</td>\n",
              "      <td>Alex is a tech enthusiast studying Computer Sc...</td>\n",
              "      <td>Computer Science</td>\n",
              "      <td>Alex is a tech enthusiast studying Computer Sc...</td>\n",
              "      <td>Alex tech enthusiast studying Computer Science...</td>\n",
              "      <td>[Alex, tech, enthusiast, studying, Computer, S...</td>\n",
              "      <td>[(Alex, NNP), (tech, VBD), (enthusiast, RB), (...</td>\n",
              "      <td>interest revolve technology computing  Alex Co...</td>\n",
              "      <td>tech studying shaping   explores</td>\n",
              "      <td>cutting-edge future</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Emily</td>\n",
              "      <td>Emily is an avid reader and historian, focusin...</td>\n",
              "      <td>Literature</td>\n",
              "      <td>Emily is an avid reader and historian , focusi...</td>\n",
              "      <td>Emily avid reader historian , focusing Literat...</td>\n",
              "      <td>[Emily, avid, reader, historian, ,, focusing, ...</td>\n",
              "      <td>[(Emily, RB), (avid, JJ), (reader, NN), (histo...</td>\n",
              "      <td>reader historian inspiration endeavor  Literat...</td>\n",
              "      <td>find  focusing drawing</td>\n",
              "      <td>avid joy deep narrative creative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>James</td>\n",
              "      <td>James is a science enthusiast excelling in Bio...</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>James is a science enthusiast excelling in Bio...</td>\n",
              "      <td>James science enthusiast excelling Biology Che...</td>\n",
              "      <td>[James, science, enthusiast, excelling, Biolog...</td>\n",
              "      <td>[(James, NNP), (science, NN), (enthusiast, NN)...</td>\n",
              "      <td>science enthusiast interest research experimen...</td>\n",
              "      <td>excelling  drive seek</td>\n",
              "      <td>unravel molecular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Mia</td>\n",
              "      <td>Mia is a student of Economics and Political Sc...</td>\n",
              "      <td>Economics</td>\n",
              "      <td>Mia is a student of Economics and Political Sc...</td>\n",
              "      <td>Mia student Economics Political Science , pass...</td>\n",
              "      <td>[Mia, student, Economics, Political, Science, ...</td>\n",
              "      <td>[(Mia, NNP), (student, NN), (Economics, NNP), ...</td>\n",
              "      <td>student passionate understanding interest comm...</td>\n",
              "      <td>making informed reflect</td>\n",
              "      <td>global dynamic positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf367ef1-1749-439a-8dc7-68d71da7d56c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf367ef1-1749-439a-8dc7-68d71da7d56c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf367ef1-1749-439a-8dc7-68d71da7d56c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09c6d56f-bdbb-4eec-ae0f-0e4f0d672042\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09c6d56f-bdbb-4eec-ae0f-0e4f0d672042')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09c6d56f-bdbb-4eec-ae0f-0e4f0d672042 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.803408430829505,\n        \"min\": 1.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28.0,\n          16.0,\n          24.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Ethan \",\n          \"Noah\",\n          \"Olivia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry's academic focus on Finance and Investment Banking reflects his interest in Financial Markets and Risk Management. Engaged in analyzing market trends and managing financial risks, he navigates the complexities of the financial world with strategic acumen.\",\n          \"Leo explores the wonders of the universe through his studies in Physics and Astronomy. With a love for Astrophotography and Cosmology, he captures the beauty of celestial objects while unraveling the mysteries of the cosmos through scientific inquiry.\",\n          \"William is a history enthusiast exploring the realms of History and Archaeology. His interests in Ancient Civilizations and Historical Preservation drive his research into the past, uncovering the stories and artifacts that shape our understanding of ancient cultures.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Evolution\",\n          \"Politics\",\n          \"Geology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry 's academic focus on Finance and Investment Banking reflects his interest in Financial Markets and Risk Management . Engaged in analyzing market trend and managing financial risk , he navigates the complexity of the financial world with strategic acumen .\",\n          \"Leo explores the wonder of the universe through his study in Physics and Astronomy . With a love for Astrophotography and Cosmology , he capture the beauty of celestial object while unraveling the mystery of the cosmos through scientific inquiry .\",\n          \"William is a history enthusiast exploring the realm of History and Archaeology . His interest in Ancient Civilizations and Historical Preservation drive his research into the past , uncovering the story and artifact that shape our understanding of ancient culture .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_lemmatized_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry 's academic focus Finance Investment Banking reflects interest Financial Markets Risk Management . Engaged analyzing market trend managing financial risk , navigates complexity financial world strategic acumen .\",\n          \"Leo explores wonder universe study Physics Astronomy . love Astrophotography Cosmology , capture beauty celestial object unraveling mystery cosmos scientific inquiry .\",\n          \"William history enthusiast exploring realm History Archaeology . interest Ancient Civilizations Historical Preservation drive research past , uncovering story artifact shape understanding ancient culture .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_array\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_tagged_words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nouns\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"focus Banking interest market trend risk world navigates acumen Henry Finance Investment Financial Markets Risk Management \",\n          \"study capture beauty object mystery cosmos inquiry  Leo Physics Astronomy Astrophotography Cosmology \",\n          \"history enthusiast interest drive research past story shape culture  William History Archaeology Civilizations Historical Preservation \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Verbs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \" Engaged analyzing managing  complexity reflects\",\n          \"love  unraveling   explores\",\n          \"  exploring uncovering understanding   \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adjectives\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"academic financial financial strategic\",\n          \"universe celestial scientific\",\n          \"realm Ancient artifact ancient\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = \"/content/Final_pd.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Function to extract tags from description\n",
        "def extract_tags(description):\n",
        "    # Tokenize the description\n",
        "    tokens = word_tokenize(description)\n",
        "    # Perform Part-of-Speech tagging\n",
        "    tagged_words = pos_tag(tokens)\n",
        "    # Define your logic to extract tags, for simplicity, let's assume the first noun encountered is the tag\n",
        "    tags = [word for word, tag in tagged_words if tag.startswith('N')]\n",
        "    return tags\n",
        "\n",
        "# Apply the function to each row to generate tags\n",
        "data['Tags'] = data['Description'].apply(extract_tags)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file if needed\n",
        "output_file_path = \"/content/Final_pd_with_tags.csv\"\n",
        "data.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BynEJYiz-7Tb",
        "outputId": "c936a5db-56a6-492b-d6b7-722dbbe7cac5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ID       Name                                        Description  \\\n",
            "0    1.0      Sarah  Sarah is a dedicated student with a passion fo...   \n",
            "1    2.0       Alex  Alex is a tech enthusiast studying Computer Sc...   \n",
            "2    3.0      Emily  Emily is an avid reader and historian, focusin...   \n",
            "3    4.0      James  James is a science enthusiast excelling in Bio...   \n",
            "4    5.0        Mia  Mia is a student of Economics and Political Sc...   \n",
            "5    6.0       Ryan  Ryan is an aspiring engineer fascinated by Rob...   \n",
            "6    7.0     Sophia  Sophia is a psychology enthusiast exploring th...   \n",
            "7    8.0      Lucas  Lucas is an art aficionado studying Art Histor...   \n",
            "8    9.0     Ethan   Ethan is a linguistics and anthropology studen...   \n",
            "9   10.0     Olivia  Olivia is a budding environmental scientist sp...   \n",
            "10  11.0       Lily  Lily is a dedicated student focusing on Chemis...   \n",
            "11  12.0        Max  Max is an aspiring Computer Engineering studen...   \n",
            "12  13.0        Ava  Ava delves into the world of language and cult...   \n",
            "13  14.0       Noah  Noah's academic focus on Economics and Finance...   \n",
            "14  15.0        Zoe  Zoe immerses herself in Political Science and ...   \n",
            "15  16.0        Leo  Leo explores the wonders of the universe throu...   \n",
            "16  17.0     Harper  Harper delves into the realms of Psychology an...   \n",
            "17  18.0      Mason  Mason's pursuits in Mechanical Engineering and...   \n",
            "18  19.0     Amelia  Amelia delves into the world of art through he...   \n",
            "19  20.0     Ethan   Ethan's academic journey in Biology and Geneti...   \n",
            "20  21.0     Sophia  Sophia is a dedicated student focusing on Soci...   \n",
            "21  22.0     Oliver  Oliver is an aspiring tech enthusiast studying...   \n",
            "22  23.0   Isabella  Isabella delves into the world of Environmenta...   \n",
            "23  24.0    William  William is a history enthusiast exploring the ...   \n",
            "24  25.0      Grace  Grace focuses on Public Health and Epidemiolog...   \n",
            "25  26.0   Benjamin  Benjamin's academic pursuits in Mechanical Eng...   \n",
            "26  27.0        Gia  Gia delves into Political Science and Human Ri...   \n",
            "27  28.0      Henry  Henry's academic focus on Finance and Investme...   \n",
            "28  29.0  Charlotte  Charlotte immerses herself in the world of Lit...   \n",
            "29  30.0      Lucas  Lucas is an art enthusiast studying Fine Arts ...   \n",
            "\n",
            "                                                 Tags  \\\n",
            "0   [Sarah, student, passion, Mathematics, Physics...   \n",
            "1   [Alex, enthusiast, Computer, Science, Data, Sc...   \n",
            "2   [reader, Literature, History, joy, Creative, W...   \n",
            "3   [James, science, enthusiast, excelling, Biolog...   \n",
            "4   [Mia, student, Economics, Political, Science, ...   \n",
            "5   [Ryan, engineer, Robotics, Renewable, Energy, ...   \n",
            "6   [Sophia, psychology, enthusiast, intricacies, ...   \n",
            "7   [Lucas, art, aficionado, Art, History, Fine, A...   \n",
            "8   [Ethan, linguistics, anthropology, student, pa...   \n",
            "9   [Olivia, scientist, Environmental, Science, Ge...   \n",
            "10  [student, Chemistry, Environmental, Science, i...   \n",
            "11  [Max, Computer, Engineering, student, interest...   \n",
            "12  [Ava, world, language, culture, studies, Lingu...   \n",
            "13  [Noah, focus, Economics, Finance, interest, in...   \n",
            "14  [Zoe, Political, Science, International, Relat...   \n",
            "15  [Leo, wonders, universe, studies, Physics, Ast...   \n",
            "16  [Harper, realms, Psychology, Behavioral, Econo...   \n",
            "17  [Mason, pursuits, Mechanical, Engineering, Rob...   \n",
            "18  [Amelia, world, art, studies, Art, History, Fi...   \n",
            "19  [Ethan, journey, Biology, Genetics, realm, eng...   \n",
            "20  [Sophia, student, Sociology, Gender, Studies, ...   \n",
            "21  [Oliver, tech, enthusiast, Computer, Science, ...   \n",
            "22  [Isabella, world, Science, Marine, Biology, fo...   \n",
            "23  [William, history, enthusiast, realms, History...   \n",
            "24  [Grace, Public, Health, Epidemiology, passion,...   \n",
            "25  [Benjamin, pursuits, Mechanical, Engineering, ...   \n",
            "26  [Gia, Science, Human, Rights, focus, Internati...   \n",
            "27  [Henry, focus, Finance, Investment, Banking, i...   \n",
            "28  [Charlotte, world, Literature, Creative, Writi...   \n",
            "29  [Lucas, art, enthusiast, Fine, Arts, Sculpture...   \n",
            "\n",
            "                               lemmatized_description  \\\n",
            "0   Sarah is a dedicated student with a passion fo...   \n",
            "1   Alex is a tech enthusiast studying Computer Sc...   \n",
            "2   Emily is an avid reader and historian , focusi...   \n",
            "3   James is a science enthusiast excelling in Bio...   \n",
            "4   Mia is a student of Economics and Political Sc...   \n",
            "5   Ryan is an aspiring engineer fascinated by Rob...   \n",
            "6   Sophia is a psychology enthusiast exploring th...   \n",
            "7   Lucas is an art aficionado studying Art Histor...   \n",
            "8   Ethan is a linguistics and anthropology studen...   \n",
            "9   Olivia is a budding environmental scientist sp...   \n",
            "10  Lily is a dedicated student focusing on Chemis...   \n",
            "11  Max is an aspiring Computer Engineering studen...   \n",
            "12  Ava delf into the world of language and cultur...   \n",
            "13  Noah 's academic focus on Economics and Financ...   \n",
            "14  Zoe immerses herself in Political Science and ...   \n",
            "15  Leo explores the wonder of the universe throug...   \n",
            "16  Harper delf into the realm of Psychology and B...   \n",
            "17  Mason 's pursuit in Mechanical Engineering and...   \n",
            "18  Amelia delf into the world of art through her ...   \n",
            "19  Ethan 's academic journey in Biology and Genet...   \n",
            "20  Sophia is a dedicated student focusing on Soci...   \n",
            "21  Oliver is an aspiring tech enthusiast studying...   \n",
            "22  Isabella delf into the world of Environmental ...   \n",
            "23  William is a history enthusiast exploring the ...   \n",
            "24  Grace focus on Public Health and Epidemiology ...   \n",
            "25  Benjamin 's academic pursuit in Mechanical Eng...   \n",
            "26  Gia delf into Political Science and Human Righ...   \n",
            "27  Henry 's academic focus on Finance and Investm...   \n",
            "28  Charlotte immerses herself in the world of Lit...   \n",
            "29  Lucas is an art enthusiast studying Fine Arts ...   \n",
            "\n",
            "                       cleaned_lemmatized_description  \\\n",
            "0   Sarah dedicated student passion Mathematics Ph...   \n",
            "1   Alex tech enthusiast studying Computer Science...   \n",
            "2   Emily avid reader historian , focusing Literat...   \n",
            "3   James science enthusiast excelling Biology Che...   \n",
            "4   Mia student Economics Political Science , pass...   \n",
            "5   Ryan aspiring engineer fascinated Robotics Ren...   \n",
            "6   Sophia psychology enthusiast exploring intrica...   \n",
            "7   Lucas art aficionado studying Art History Fine...   \n",
            "8   Ethan linguistics anthropology student passion...   \n",
            "9   Olivia budding environmental scientist special...   \n",
            "10  Lily dedicated student focusing Chemistry Envi...   \n",
            "11  Max aspiring Computer Engineering student keen...   \n",
            "12  Ava delf world language culture study Linguist...   \n",
            "13  Noah 's academic focus Economics Finance refle...   \n",
            "14  Zoe immerses Political Science International R...   \n",
            "15  Leo explores wonder universe study Physics Ast...   \n",
            "16  Harper delf realm Psychology Behavioral Econom...   \n",
            "17  Mason 's pursuit Mechanical Engineering Roboti...   \n",
            "18  Amelia delf world art study Art History Fine A...   \n",
            "19  Ethan 's academic journey Biology Genetics lea...   \n",
            "20  Sophia dedicated student focusing Sociology Ge...   \n",
            "21  Oliver aspiring tech enthusiast studying Compu...   \n",
            "22  Isabella delf world Environmental Science Mari...   \n",
            "23  William history enthusiast exploring realm His...   \n",
            "24  Grace focus Public Health Epidemiology , passi...   \n",
            "25  Benjamin 's academic pursuit Mechanical Engine...   \n",
            "26  Gia delf Political Science Human Rights , focu...   \n",
            "27  Henry 's academic focus Finance Investment Ban...   \n",
            "28  Charlotte immerses world Literature Creative W...   \n",
            "29  Lucas art enthusiast studying Fine Arts Sculpt...   \n",
            "\n",
            "                                           word_array  \\\n",
            "0   ['Sarah', 'dedicated', 'student', 'passion', '...   \n",
            "1   ['Alex', 'tech', 'enthusiast', 'studying', 'Co...   \n",
            "2   ['Emily', 'avid', 'reader', 'historian', ',', ...   \n",
            "3   ['James', 'science', 'enthusiast', 'excelling'...   \n",
            "4   ['Mia', 'student', 'Economics', 'Political', '...   \n",
            "5   ['Ryan', 'aspiring', 'engineer', 'fascinated',...   \n",
            "6   ['Sophia', 'psychology', 'enthusiast', 'explor...   \n",
            "7   ['Lucas', 'art', 'aficionado', 'studying', 'Ar...   \n",
            "8   ['Ethan', 'linguistics', 'anthropology', 'stud...   \n",
            "9   ['Olivia', 'budding', 'environmental', 'scient...   \n",
            "10  ['Lily', 'dedicated', 'student', 'focusing', '...   \n",
            "11  ['Max', 'aspiring', 'Computer', 'Engineering',...   \n",
            "12  ['Ava', 'delf', 'world', 'language', 'culture'...   \n",
            "13  ['Noah', \"'s\", 'academic', 'focus', 'Economics...   \n",
            "14  ['Zoe', 'immerses', 'Political', 'Science', 'I...   \n",
            "15  ['Leo', 'explores', 'wonder', 'universe', 'stu...   \n",
            "16  ['Harper', 'delf', 'realm', 'Psychology', 'Beh...   \n",
            "17  ['Mason', \"'s\", 'pursuit', 'Mechanical', 'Engi...   \n",
            "18  ['Amelia', 'delf', 'world', 'art', 'study', 'A...   \n",
            "19  ['Ethan', \"'s\", 'academic', 'journey', 'Biolog...   \n",
            "20  ['Sophia', 'dedicated', 'student', 'focusing',...   \n",
            "21  ['Oliver', 'aspiring', 'tech', 'enthusiast', '...   \n",
            "22  ['Isabella', 'delf', 'world', 'Environmental',...   \n",
            "23  ['William', 'history', 'enthusiast', 'explorin...   \n",
            "24  ['Grace', 'focus', 'Public', 'Health', 'Epidem...   \n",
            "25  ['Benjamin', \"'s\", 'academic', 'pursuit', 'Mec...   \n",
            "26  ['Gia', 'delf', 'Political', 'Science', 'Human...   \n",
            "27  ['Henry', \"'s\", 'academic', 'focus', 'Finance'...   \n",
            "28  ['Charlotte', 'immerses', 'world', 'Literature...   \n",
            "29  ['Lucas', 'art', 'enthusiast', 'studying', 'Fi...   \n",
            "\n",
            "                                     pos_tagged_words  \\\n",
            "0   [('Sarah', 'NNP'), ('dedicated', 'VBD'), ('stu...   \n",
            "1   [('Alex', 'NNP'), ('tech', 'VBD'), ('enthusias...   \n",
            "2   [('Emily', 'RB'), ('avid', 'JJ'), ('reader', '...   \n",
            "3   [('James', 'NNP'), ('science', 'NN'), ('enthus...   \n",
            "4   [('Mia', 'NNP'), ('student', 'NN'), ('Economic...   \n",
            "5   [('Ryan', 'JJ'), ('aspiring', 'VBG'), ('engine...   \n",
            "6   [('Sophia', 'NNP'), ('psychology', 'NN'), ('en...   \n",
            "7   [('Lucas', 'NNP'), ('art', 'NN'), ('aficionado...   \n",
            "8   [('Ethan', 'NNP'), ('linguistics', 'NNS'), ('a...   \n",
            "9   [('Olivia', 'NNP'), ('budding', 'VBG'), ('envi...   \n",
            "10  [('Lily', 'RB'), ('dedicated', 'VBN'), ('stude...   \n",
            "11  [('Max', 'NNP'), ('aspiring', 'VBG'), ('Comput...   \n",
            "12  [('Ava', 'NNP'), ('delf', 'PRP'), ('world', 'N...   \n",
            "13  [('Noah', 'NNP'), (\"'s\", 'POS'), ('academic', ...   \n",
            "14  [('Zoe', 'JJ'), ('immerses', 'VBZ'), ('Politic...   \n",
            "15  [('Leo', 'NNP'), ('explores', 'VBZ'), ('wonder...   \n",
            "16  [('Harper', 'NNP'), ('delf', 'PRP'), ('realm',...   \n",
            "17  [('Mason', 'NNP'), (\"'s\", 'POS'), ('pursuit', ...   \n",
            "18  [('Amelia', 'NNP'), ('delf', 'PRP'), ('world',...   \n",
            "19  [('Ethan', 'NNP'), (\"'s\", 'POS'), ('academic',...   \n",
            "20  [('Sophia', 'NNP'), ('dedicated', 'VBD'), ('st...   \n",
            "21  [('Oliver', 'IN'), ('aspiring', 'VBG'), ('tech...   \n",
            "22  [('Isabella', 'NNP'), ('delf', 'PRP'), ('world...   \n",
            "23  [('William', 'NNP'), ('history', 'NN'), ('enth...   \n",
            "24  [('Grace', 'NNP'), ('focus', 'VBZ'), ('Public'...   \n",
            "25  [('Benjamin', 'NNP'), (\"'s\", 'POS'), ('academi...   \n",
            "26  [('Gia', 'NNP'), ('delf', 'PRP'), ('Political'...   \n",
            "27  [('Henry', 'NNP'), (\"'s\", 'POS'), ('academic',...   \n",
            "28  [('Charlotte', 'NNP'), ('immerses', 'VBZ'), ('...   \n",
            "29  [('Lucas', 'NNP'), ('art', 'NN'), ('enthusiast...   \n",
            "\n",
            "                                                Nouns  \\\n",
            "0   student passion interest lie realm fervor curi...   \n",
            "1   interest revolve technology computing  Alex Co...   \n",
            "2   reader historian inspiration endeavor  Literat...   \n",
            "3   science enthusiast interest research experimen...   \n",
            "4   student passionate understanding interest comm...   \n",
            "5   engineer interest technology drive project fut...   \n",
            "6   psychology enthusiast intricacy behavior study...   \n",
            "7   art aficionado interest expression form meanin...   \n",
            "8   student passionate language culture interest L...   \n",
            "9   scientist interest propel study understand sys...   \n",
            "10  student interest lie apply knowledge address c...   \n",
            "11  student interest passion exploration secure sy...   \n",
            "12  world language culture study fascination aim b...   \n",
            "13  focus interest intricacy market trend precisio...   \n",
            "14  passion diplomacy governance interest Diplomac...   \n",
            "15  study capture beauty object mystery cosmos inq...   \n",
            "16  complexity process interest make choice contex...   \n",
            "17  pursuit fascination automation interest Automa...   \n",
            "18  world art focus Art creativity form art trend ...   \n",
            "19  journey realm engineering biotechnology intere...   \n",
            "20  student interest lie structure advocate equali...   \n",
            "21  tech enthusiast interest passion software solu...   \n",
            "22  world marine ecosystem life  Isabella Environm...   \n",
            "23  history enthusiast interest drive research pas...   \n",
            "24  passion initiative dedication health drive res...   \n",
            "25  pursuit reflect fascination interest aerospace...   \n",
            "26  passion right justice scale fuel commitment fr...   \n",
            "27  focus Banking interest market trend risk world...   \n",
            "28  world passion expression word love art power i...   \n",
            "29  art enthusiast interest inspire endeavor art f...   \n",
            "\n",
            "                                                Verbs  \\\n",
            "0                                dedicated   mystery    \n",
            "1                    tech studying shaping   explores   \n",
            "2                           find  focusing drawing      \n",
            "3                              excelling  drive seek    \n",
            "4                            making informed reflect    \n",
            "5                       fascinated aspiring aiming      \n",
            "6                                        exploring      \n",
            "7                          studying  inspire explores   \n",
            "8                                 anthropology drive    \n",
            "9                      budding specializing  protect    \n",
            "10                               focusing dedicated     \n",
            "11                                 aspiring aiming      \n",
            "12                                   understanding      \n",
            "13                                 reflects navigates   \n",
            "14                                contribute immerses   \n",
            "15                        love  unraveling   explores   \n",
            "16                       exploring  realm understand    \n",
            "17                                           reflect    \n",
            "18                                  exploring  study    \n",
            "19                                           explores   \n",
            "20                      dedicated focusing   explores   \n",
            "21        aspiring studying creating ensuring  drive    \n",
            "22             focus committed protecting studying      \n",
            "23              exploring uncovering understanding      \n",
            "24             promoting preventing improving   focus   \n",
            "25                                         pushing      \n",
            "26    promoting advocating advocating marginalized...   \n",
            "27    Engaged analyzing managing  complexity reflects   \n",
            "28                            storytelling   immerses   \n",
            "29                       studying  challenge explores   \n",
            "\n",
            "                                           Adjectives  \n",
            "0                                            universe  \n",
            "1                                 cutting-edge future  \n",
            "2                    avid joy deep narrative creative  \n",
            "3                                   unravel molecular  \n",
            "4                             global dynamic positive  \n",
            "5   Ryan Autonomous sustainable innovative create ...  \n",
            "6                    human mental well-being societal  \n",
            "7              Contemporary creative diverse artistic  \n",
            "8                                                 NaN  \n",
            "9                   environmental seek natural future  \n",
            "10                                 seek environmental  \n",
            "11                         keen drive ethical digital  \n",
            "12                                 linguistic diverse  \n",
            "13  academic financial Engaged complexity economic...  \n",
            "14  Zoe Political driven global international peac...  \n",
            "15                      universe celestial scientific  \n",
            "16  human behavior decision-making seek individual...  \n",
            "17                              innovative mechanical  \n",
            "18         Contemporary Mixed express artistic modern  \n",
            "19  academic lead genetic cutting-edge advancement...  \n",
            "20                        complexity societal diverse  \n",
            "21                                 innovative digital  \n",
            "22                            intricate dynamic ocean  \n",
            "23                     realm Ancient artifact ancient  \n",
            "24                                         well-being  \n",
            "25                       academic boundary innovative  \n",
            "26                   human global understanding legal  \n",
            "27             academic financial financial strategic  \n",
            "28                          creative reflect literary  \n",
            "29       Contemporary creative innovative traditional  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = \"/content/Final_pd.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Function to extract tags from description\n",
        "def extract_tags(description):\n",
        "    # Tokenize the description\n",
        "    tokens = word_tokenize(description)\n",
        "    # Perform Part-of-Speech tagging\n",
        "    tagged_words = pos_tag(tokens)\n",
        "    # Define your logic to extract tags, for simplicity, let's assume the first noun encountered is the tag\n",
        "    tags = [word for word, tag in tagged_words if tag.startswith('N')]\n",
        "    return tags\n",
        "\n",
        "# Create a dictionary to map names to tags\n",
        "name_tag_dict = {}\n",
        "\n",
        "# Iterate over each row to generate tags and map them to names\n",
        "for index, row in data.iterrows():\n",
        "    name = row['Name']\n",
        "    description = row['Description']\n",
        "    tags = extract_tags(description)\n",
        "    name_tag_dict[name] = tags\n",
        "\n",
        "# Display the dictionary\n",
        "print(name_tag_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic9mQupDAPL4",
        "outputId": "fed6fa86-9363-47be-ae7b-d24a278e24f6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Sarah': ['Sarah', 'student', 'passion', 'Mathematics', 'Physics', 'interests', 'realms', 'Astrophysics', 'Quantum', 'Mechanics', 'mysteries', 'universe', 'fervor', 'curiosity'], 'Alex': ['Alex', 'enthusiast', 'Computer', 'Science', 'Data', 'Science', 'interests', 'Artificial', 'Intelligence', 'Machine', 'Learning', 'cutting-edge', 'technologies', 'future'], 'Emily': ['reader', 'Literature', 'History', 'joy', 'Creative', 'Writing', 'narratives', 'Ancient', 'Civilizations', 'inspiration', 'past', 'endeavors'], 'James': ['James', 'science', 'enthusiast', 'excelling', 'Biology', 'Chemistry', 'interests', 'Genetics', 'Biochemistry', 'research', 'experiments', 'complexities', 'life', 'level'], 'Mia': ['Mia', 'student', 'Economics', 'Political', 'Science', 'passionate', 'dynamics', 'interests', 'International', 'Relations', 'Public', 'Policy', 'commitment', 'impact', 'society', 'decision-making'], 'Ryan': ['Ryan', 'engineer', 'Robotics', 'Renewable', 'Energy', 'interests', 'Systems', 'technologies', 'projects', 'future'], 'Sophia': ['Sophia', 'student', 'Sociology', 'Gender', 'Studies', 'interests', 'Social', 'Justice', 'Intersectionality', 'complexities', 'structures', 'advocates', 'equality', 'communities'], 'Lucas': ['Lucas', 'art', 'enthusiast', 'Fine', 'Arts', 'Sculpture', 'interests', 'Contemporary', 'Art', 'Installation', 'Art', 'endeavors', 'art', 'forms', 'expressions', 'boundaries'], 'Ethan ': ['Ethan', 'journey', 'Biology', 'Genetics', 'realm', 'engineering', 'biotechnology', 'interests', 'Genetic', 'Engineering', 'Biotechnology', 'advancements', 'manipulation', 'applications', 'healthcare'], 'Olivia': ['Olivia', 'scientist', 'Environmental', 'Science', 'Geology', 'interests', 'Climate', 'Change', 'Research', 'Geological', 'Mapping', 'studies', 'Earth', 'systems', 'generations'], 'Lily': ['student', 'Chemistry', 'Environmental', 'Science', 'interests', 'Chemistry', 'Climate', 'Change', 'Mitigation', 'knowledge', 'challenges', 'sustainability'], 'Max': ['Max', 'Computer', 'Engineering', 'student', 'interest', 'Cybersecurity', 'passion', 'Network', 'Security', 'Ethical', 'Hacking', 'exploration', 'secure', 'systems', 'hacking', 'practices', 'world'], 'Ava': ['Ava', 'world', 'language', 'culture', 'studies', 'Linguistics', 'Translation', 'Studies', 'fascination', 'Multilingualism', 'Cross-Cultural', 'Communication', 'gaps', 'foster', 'communities'], 'Noah': ['Noah', 'focus', 'Economics', 'Finance', 'interest', 'intricacies', 'markets', 'Stock', 'Market', 'Analysis', 'Financial', 'Planning', 'complexities', 'trends', 'decision-making', 'precision'], 'Zoe': ['Zoe', 'Political', 'Science', 'International', 'Relations', 'passion', 'diplomacy', 'governance', 'interests', 'Diplomacy', 'Global', 'Affairs', 'aspirations', 'cooperation', 'efforts'], 'Leo': ['Leo', 'wonders', 'universe', 'studies', 'Physics', 'Astronomy', 'love', 'Astrophotography', 'Cosmology', 'beauty', 'objects', 'mysteries', 'cosmos', 'inquiry'], 'Harper': ['Harper', 'realms', 'Psychology', 'Behavioral', 'Economics', 'complexities', 'behavior', 'processes', 'interests', 'Cognitive', 'Psychology', 'Behavioral', 'Economics', 'individuals', 'choices', 'contexts'], 'Mason': ['Mason', 'pursuits', 'Mechanical', 'Engineering', 'Robotics', 'fascination', 'automation', 'biomechanics', 'interests', 'Automation', 'Robotics', 'exploration', 'technologies', 'efficiency', 'functionality', 'systems'], 'Amelia': ['Amelia', 'world', 'art', 'studies', 'Art', 'History', 'Fine', 'Arts', 'focus', 'Contemporary', 'Art', 'Movements', 'Mixed', 'Media', 'creativity', 'forms', 'art', 'trends', 'techniques'], 'Oliver': ['Oliver', 'tech', 'enthusiast', 'Computer', 'Science', 'Software', 'Engineering', 'interests', 'App', 'Development', 'Cybersecurity', 'passion', 'software', 'solutions', 'security'], 'Isabella': ['Isabella', 'world', 'Science', 'Marine', 'Biology', 'focus', 'Marine', 'Conservation', 'Oceanography', 'ecosystems', 'dynamics', 'life'], 'William': ['William', 'history', 'enthusiast', 'realms', 'History', 'Archaeology', 'interests', 'Ancient', 'Civilizations', 'Historical', 'Preservation', 'research', 'stories', 'artifacts', 'understanding', 'cultures'], 'Grace': ['Grace', 'Public', 'Health', 'Epidemiology', 'passion', 'Disease', 'Prevention', 'Global', 'Health', 'initiatives', 'dedication', 'health', 'drives', 'research', 'diseases', 'systems', 'worldwide'], 'Benjamin': ['Benjamin', 'pursuits', 'Mechanical', 'Engineering', 'Aerospace', 'Engineering', 'fascination', 'Space', 'Exploration', 'Aerodynamics', 'interests', 'boundaries', 'aerospace', 'technology', 'drive', 'exploration', 'engineering', 'solutions', 'space', 'travel'], 'Gia': ['Gia', 'Science', 'Human', 'Rights', 'focus', 'International', 'Law', 'Advocacy', 'passion', 'rights', 'justice', 'scale', 'fuels', 'commitment', 'frameworks', 'communities'], 'Henry': ['Henry', 'focus', 'Finance', 'Investment', 'Banking', 'interest', 'Financial', 'Markets', 'Risk', 'Management', 'market', 'trends', 'risks', 'complexities', 'world', 'acumen'], 'Charlotte': ['Charlotte', 'world', 'Literature', 'Creative', 'Writing', 'passion', 'Poetry', 'Fiction', 'Writing', 'expressions', 'words', 'love', 'arts', 'power', 'imagination']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = \"/content/Final_pd.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Function to extract tags from description\n",
        "def extract_tags(description):\n",
        "    # Tokenize the description\n",
        "    tokens = word_tokenize(description)\n",
        "    # Perform Part-of-Speech tagging\n",
        "    tagged_words = pos_tag(tokens)\n",
        "    # Define your logic to extract tags, for simplicity, let's assume the first noun encountered is the tag\n",
        "    tags = [word for word, tag in tagged_words if tag.startswith('N')]\n",
        "    return ' '.join(tags)\n",
        "\n",
        "# Preprocess data\n",
        "data['tags'] = data['Description'].apply(extract_tags)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Description'], data['tags'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline with CountVectorizer and Multinomial Naive Bayes\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "\n",
        "# Train the model\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "predicted = text_clf.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", text_clf.score(X_test, y_test))\n",
        "\n",
        "# Example usage: Predict tags for a given phrase\n",
        "def predict_tags(phrase):\n",
        "    predicted_tags = text_clf.predict([phrase])\n",
        "    return predicted_tags\n",
        "\n",
        "# Example usage\n",
        "phrase = \"Student is very much interested in Mathematics and Physics\"\n",
        "predicted_tags = predict_tags(phrase)\n",
        "print(\"Predicted tags for the phrase:\", predicted_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVowohXDBfVP",
        "outputId": "829aa340-7167-479f-8c4b-c803ea349d3e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Predicted tags for the phrase: ['Sarah student passion Mathematics Physics interests realms Astrophysics Quantum Mechanics mysteries universe fervor curiosity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEW APPROACH"
      ],
      "metadata": {
        "id": "X8PhXjI0NUk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# Assuming 'Description' is a column in your DataFrame\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"/content/Final_pd.csv\")\n",
        "\n",
        "# Initialize NLTK tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_and_tokenize(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize\n",
        "    words = word_tokenize(text)\n",
        "    # Remove stop words and lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing\n",
        "df['Processed'] = df['cleaned_lemmatized_description'].apply(preprocess_and_tokenize)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4gJfJNMB1oB",
        "outputId": "d729d5dc-cee2-4e4e-b00c-ad883f09564a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_terms(tokens):\n",
        "    # Count term frequencies\n",
        "    term_freq = Counter(tokens)\n",
        "    # Sort terms by frequency\n",
        "    sorted_terms = dict(sorted(term_freq.items(), key=lambda item: item[1], reverse=True))\n",
        "    return sorted_terms\n",
        "\n",
        "# Score and rank terms in descriptions\n",
        "df['Ranked_Terms'] = df['Processed'].apply(score_terms)\n"
      ],
      "metadata": {
        "id": "GYck6cOwNWis"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_top_n_tags(ranked_terms, n=7):\n",
        "    # Select the top N terms\n",
        "    return list(ranked_terms.keys())[:n]\n",
        "\n",
        "df['Top_7_Tags'] = df['Ranked_Terms'].apply(lambda x: select_top_n_tags(x, 7))\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "Fm4DNDvsOKVy",
        "outputId": "1bcccfea-18d3-4636-9b04-dad52dceeba6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID   Name                                        Description  \\\n",
              "0  1.0  Sarah  Sarah is a dedicated student with a passion fo...   \n",
              "1  2.0   Alex  Alex is a tech enthusiast studying Computer Sc...   \n",
              "2  3.0  Emily  Emily is an avid reader and historian, focusin...   \n",
              "3  4.0  James  James is a science enthusiast excelling in Bio...   \n",
              "4  5.0    Mia  Mia is a student of Economics and Political Sc...   \n",
              "\n",
              "               Tags                             lemmatized_description  \\\n",
              "0           Physics  Sarah is a dedicated student with a passion fo...   \n",
              "1  Computer Science  Alex is a tech enthusiast studying Computer Sc...   \n",
              "2        Literature  Emily is an avid reader and historian , focusi...   \n",
              "3         Chemistry  James is a science enthusiast excelling in Bio...   \n",
              "4         Economics  Mia is a student of Economics and Political Sc...   \n",
              "\n",
              "                      cleaned_lemmatized_description  \\\n",
              "0  Sarah dedicated student passion Mathematics Ph...   \n",
              "1  Alex tech enthusiast studying Computer Science...   \n",
              "2  Emily avid reader historian , focusing Literat...   \n",
              "3  James science enthusiast excelling Biology Che...   \n",
              "4  Mia student Economics Political Science , pass...   \n",
              "\n",
              "                                          word_array  \\\n",
              "0  ['Sarah', 'dedicated', 'student', 'passion', '...   \n",
              "1  ['Alex', 'tech', 'enthusiast', 'studying', 'Co...   \n",
              "2  ['Emily', 'avid', 'reader', 'historian', ',', ...   \n",
              "3  ['James', 'science', 'enthusiast', 'excelling'...   \n",
              "4  ['Mia', 'student', 'Economics', 'Political', '...   \n",
              "\n",
              "                                    pos_tagged_words  \\\n",
              "0  [('Sarah', 'NNP'), ('dedicated', 'VBD'), ('stu...   \n",
              "1  [('Alex', 'NNP'), ('tech', 'VBD'), ('enthusias...   \n",
              "2  [('Emily', 'RB'), ('avid', 'JJ'), ('reader', '...   \n",
              "3  [('James', 'NNP'), ('science', 'NN'), ('enthus...   \n",
              "4  [('Mia', 'NNP'), ('student', 'NN'), ('Economic...   \n",
              "\n",
              "                                               Nouns  \\\n",
              "0  student passion interest lie realm fervor curi...   \n",
              "1  interest revolve technology computing  Alex Co...   \n",
              "2  reader historian inspiration endeavor  Literat...   \n",
              "3  science enthusiast interest research experimen...   \n",
              "4  student passionate understanding interest comm...   \n",
              "\n",
              "                               Verbs                        Adjectives  \\\n",
              "0               dedicated   mystery                           universe   \n",
              "1   tech studying shaping   explores               cutting-edge future   \n",
              "2          find  focusing drawing     avid joy deep narrative creative   \n",
              "3             excelling  drive seek                  unravel molecular   \n",
              "4           making informed reflect            global dynamic positive   \n",
              "\n",
              "                                           Processed  \\\n",
              "0  [sarah, dedicated, student, passion, mathemati...   \n",
              "1  [alex, tech, enthusiast, studying, computer, s...   \n",
              "2  [emily, avid, reader, historian, focusing, lit...   \n",
              "3  [james, science, enthusiast, excelling, biolog...   \n",
              "4  [mia, student, economics, political, science, ...   \n",
              "\n",
              "                                        Ranked_Terms  \\\n",
              "0  {'sarah': 1, 'dedicated': 1, 'student': 1, 'pa...   \n",
              "1  {'science': 2, 'alex': 1, 'tech': 1, 'enthusia...   \n",
              "2  {'creative': 2, 'emily': 1, 'avid': 1, 'reader...   \n",
              "3  {'james': 1, 'science': 1, 'enthusiast': 1, 'e...   \n",
              "4  {'mia': 1, 'student': 1, 'economics': 1, 'poli...   \n",
              "\n",
              "                                          Top_7_Tags  \n",
              "0  [sarah, dedicated, student, passion, mathemati...  \n",
              "1  [science, alex, tech, enthusiast, studying, co...  \n",
              "2  [creative, emily, avid, reader, historian, foc...  \n",
              "3  [james, science, enthusiast, excelling, biolog...  \n",
              "4  [mia, student, economics, political, science, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a8a598f-e9a4-4ffe-ae4c-a419ac0e03fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>Tags</th>\n",
              "      <th>lemmatized_description</th>\n",
              "      <th>cleaned_lemmatized_description</th>\n",
              "      <th>word_array</th>\n",
              "      <th>pos_tagged_words</th>\n",
              "      <th>Nouns</th>\n",
              "      <th>Verbs</th>\n",
              "      <th>Adjectives</th>\n",
              "      <th>Processed</th>\n",
              "      <th>Ranked_Terms</th>\n",
              "      <th>Top_7_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Sarah</td>\n",
              "      <td>Sarah is a dedicated student with a passion fo...</td>\n",
              "      <td>Physics</td>\n",
              "      <td>Sarah is a dedicated student with a passion fo...</td>\n",
              "      <td>Sarah dedicated student passion Mathematics Ph...</td>\n",
              "      <td>['Sarah', 'dedicated', 'student', 'passion', '...</td>\n",
              "      <td>[('Sarah', 'NNP'), ('dedicated', 'VBD'), ('stu...</td>\n",
              "      <td>student passion interest lie realm fervor curi...</td>\n",
              "      <td>dedicated   mystery</td>\n",
              "      <td>universe</td>\n",
              "      <td>[sarah, dedicated, student, passion, mathemati...</td>\n",
              "      <td>{'sarah': 1, 'dedicated': 1, 'student': 1, 'pa...</td>\n",
              "      <td>[sarah, dedicated, student, passion, mathemati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Alex</td>\n",
              "      <td>Alex is a tech enthusiast studying Computer Sc...</td>\n",
              "      <td>Computer Science</td>\n",
              "      <td>Alex is a tech enthusiast studying Computer Sc...</td>\n",
              "      <td>Alex tech enthusiast studying Computer Science...</td>\n",
              "      <td>['Alex', 'tech', 'enthusiast', 'studying', 'Co...</td>\n",
              "      <td>[('Alex', 'NNP'), ('tech', 'VBD'), ('enthusias...</td>\n",
              "      <td>interest revolve technology computing  Alex Co...</td>\n",
              "      <td>tech studying shaping   explores</td>\n",
              "      <td>cutting-edge future</td>\n",
              "      <td>[alex, tech, enthusiast, studying, computer, s...</td>\n",
              "      <td>{'science': 2, 'alex': 1, 'tech': 1, 'enthusia...</td>\n",
              "      <td>[science, alex, tech, enthusiast, studying, co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Emily</td>\n",
              "      <td>Emily is an avid reader and historian, focusin...</td>\n",
              "      <td>Literature</td>\n",
              "      <td>Emily is an avid reader and historian , focusi...</td>\n",
              "      <td>Emily avid reader historian , focusing Literat...</td>\n",
              "      <td>['Emily', 'avid', 'reader', 'historian', ',', ...</td>\n",
              "      <td>[('Emily', 'RB'), ('avid', 'JJ'), ('reader', '...</td>\n",
              "      <td>reader historian inspiration endeavor  Literat...</td>\n",
              "      <td>find  focusing drawing</td>\n",
              "      <td>avid joy deep narrative creative</td>\n",
              "      <td>[emily, avid, reader, historian, focusing, lit...</td>\n",
              "      <td>{'creative': 2, 'emily': 1, 'avid': 1, 'reader...</td>\n",
              "      <td>[creative, emily, avid, reader, historian, foc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>James</td>\n",
              "      <td>James is a science enthusiast excelling in Bio...</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>James is a science enthusiast excelling in Bio...</td>\n",
              "      <td>James science enthusiast excelling Biology Che...</td>\n",
              "      <td>['James', 'science', 'enthusiast', 'excelling'...</td>\n",
              "      <td>[('James', 'NNP'), ('science', 'NN'), ('enthus...</td>\n",
              "      <td>science enthusiast interest research experimen...</td>\n",
              "      <td>excelling  drive seek</td>\n",
              "      <td>unravel molecular</td>\n",
              "      <td>[james, science, enthusiast, excelling, biolog...</td>\n",
              "      <td>{'james': 1, 'science': 1, 'enthusiast': 1, 'e...</td>\n",
              "      <td>[james, science, enthusiast, excelling, biolog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Mia</td>\n",
              "      <td>Mia is a student of Economics and Political Sc...</td>\n",
              "      <td>Economics</td>\n",
              "      <td>Mia is a student of Economics and Political Sc...</td>\n",
              "      <td>Mia student Economics Political Science , pass...</td>\n",
              "      <td>['Mia', 'student', 'Economics', 'Political', '...</td>\n",
              "      <td>[('Mia', 'NNP'), ('student', 'NN'), ('Economic...</td>\n",
              "      <td>student passionate understanding interest comm...</td>\n",
              "      <td>making informed reflect</td>\n",
              "      <td>global dynamic positive</td>\n",
              "      <td>[mia, student, economics, political, science, ...</td>\n",
              "      <td>{'mia': 1, 'student': 1, 'economics': 1, 'poli...</td>\n",
              "      <td>[mia, student, economics, political, science, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a8a598f-e9a4-4ffe-ae4c-a419ac0e03fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a8a598f-e9a4-4ffe-ae4c-a419ac0e03fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a8a598f-e9a4-4ffe-ae4c-a419ac0e03fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5620a847-5cd9-4f65-a410-f3008a0f3723\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5620a847-5cd9-4f65-a410-f3008a0f3723')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5620a847-5cd9-4f65-a410-f3008a0f3723 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.803408430829505,\n        \"min\": 1.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28.0,\n          16.0,\n          24.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Ethan \",\n          \"Noah\",\n          \"Olivia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry's academic focus on Finance and Investment Banking reflects his interest in Financial Markets and Risk Management. Engaged in analyzing market trends and managing financial risks, he navigates the complexities of the financial world with strategic acumen.\",\n          \"Leo explores the wonders of the universe through his studies in Physics and Astronomy. With a love for Astrophotography and Cosmology, he captures the beauty of celestial objects while unraveling the mysteries of the cosmos through scientific inquiry.\",\n          \"William is a history enthusiast exploring the realms of History and Archaeology. His interests in Ancient Civilizations and Historical Preservation drive his research into the past, uncovering the stories and artifacts that shape our understanding of ancient cultures.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Evolution\",\n          \"Politics\",\n          \"Geology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry 's academic focus on Finance and Investment Banking reflects his interest in Financial Markets and Risk Management . Engaged in analyzing market trend and managing financial risk , he navigates the complexity of the financial world with strategic acumen .\",\n          \"Leo explores the wonder of the universe through his study in Physics and Astronomy . With a love for Astrophotography and Cosmology , he capture the beauty of celestial object while unraveling the mystery of the cosmos through scientific inquiry .\",\n          \"William is a history enthusiast exploring the realm of History and Archaeology . His interest in Ancient Civilizations and Historical Preservation drive his research into the past , uncovering the story and artifact that shape our understanding of ancient culture .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_lemmatized_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Henry 's academic focus Finance Investment Banking reflects interest Financial Markets Risk Management . Engaged analyzing market trend managing financial risk , navigates complexity financial world strategic acumen .\",\n          \"Leo explores wonder universe study Physics Astronomy . love Astrophotography Cosmology , capture beauty celestial object unraveling mystery cosmos scientific inquiry .\",\n          \"William history enthusiast exploring realm History Archaeology . interest Ancient Civilizations Historical Preservation drive research past , uncovering story artifact shape understanding ancient culture .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_array\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"['Henry', \\\"'s\\\", 'academic', 'focus', 'Finance', 'Investment', 'Banking', 'reflects', 'interest', 'Financial', 'Markets', 'Risk', 'Management', '.', 'Engaged', 'analyzing', 'market', 'trend', 'managing', 'financial', 'risk', ',', 'navigates', 'complexity', 'financial', 'world', 'strategic', 'acumen', '.']\",\n          \"['Leo', 'explores', 'wonder', 'universe', 'study', 'Physics', 'Astronomy', '.', 'love', 'Astrophotography', 'Cosmology', ',', 'capture', 'beauty', 'celestial', 'object', 'unraveling', 'mystery', 'cosmos', 'scientific', 'inquiry', '.']\",\n          \"['William', 'history', 'enthusiast', 'exploring', 'realm', 'History', 'Archaeology', '.', 'interest', 'Ancient', 'Civilizations', 'Historical', 'Preservation', 'drive', 'research', 'past', ',', 'uncovering', 'story', 'artifact', 'shape', 'understanding', 'ancient', 'culture', '.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_tagged_words\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"[('Henry', 'NNP'), (\\\"'s\\\", 'POS'), ('academic', 'JJ'), ('focus', 'NN'), ('Finance', 'NNP'), ('Investment', 'NNP'), ('Banking', 'NN'), ('reflects', 'VBZ'), ('interest', 'NN'), ('Financial', 'NNP'), ('Markets', 'NNP'), ('Risk', 'NNP'), ('Management', 'NNP'), ('.', '.'), ('Engaged', 'VBD'), ('analyzing', 'VBG'), ('market', 'NN'), ('trend', 'NN'), ('managing', 'VBG'), ('financial', 'JJ'), ('risk', 'NN'), (',', ','), ('navigates', 'NNS'), ('complexity', 'VBP'), ('financial', 'JJ'), ('world', 'NN'), ('strategic', 'JJ'), ('acumen', 'NNS'), ('.', '.')]\",\n          \"[('Leo', 'NNP'), ('explores', 'VBZ'), ('wonder', 'JJR'), ('universe', 'JJ'), ('study', 'NN'), ('Physics', 'NNP'), ('Astronomy', 'NNP'), ('.', '.'), ('love', 'VB'), ('Astrophotography', 'NNP'), ('Cosmology', 'NNP'), (',', ','), ('capture', 'NN'), ('beauty', 'NN'), ('celestial', 'JJ'), ('object', 'NN'), ('unraveling', 'VBG'), ('mystery', 'NN'), ('cosmos', 'NN'), ('scientific', 'JJ'), ('inquiry', 'NN'), ('.', '.')]\",\n          \"[('William', 'NNP'), ('history', 'NN'), ('enthusiast', 'NN'), ('exploring', 'VBG'), ('realm', 'JJ'), ('History', 'NNP'), ('Archaeology', 'NNP'), ('.', '.'), ('interest', 'NN'), ('Ancient', 'JJ'), ('Civilizations', 'NNP'), ('Historical', 'NNP'), ('Preservation', 'NNP'), ('drive', 'NN'), ('research', 'NN'), ('past', 'NN'), (',', ','), ('uncovering', 'VBG'), ('story', 'NN'), ('artifact', 'JJ'), ('shape', 'NN'), ('understanding', 'VBG'), ('ancient', 'JJ'), ('culture', 'NN'), ('.', '.')]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nouns\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"focus Banking interest market trend risk world navigates acumen Henry Finance Investment Financial Markets Risk Management \",\n          \"study capture beauty object mystery cosmos inquiry  Leo Physics Astronomy Astrophotography Cosmology \",\n          \"history enthusiast interest drive research past story shape culture  William History Archaeology Civilizations Historical Preservation \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Verbs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \" Engaged analyzing managing  complexity reflects\",\n          \"love  unraveling   explores\",\n          \"  exploring uncovering understanding   \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adjectives\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"creative reflect literary\",\n          \"innovative mechanical\",\n          \"academic financial Engaged complexity economic financial decision-making\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Processed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ranked_Terms\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Top_7_Tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map names to their top 5 tags\n",
        "name_to_top_tags = pd.Series(df['Top_7_Tags'].values, index=df['Name']).to_dict()\n",
        "\n",
        "print(name_to_top_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2oRQt38OM0J",
        "outputId": "6b829c28-2d32-4f90-9198-7d0057b1bb2d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Sarah': ['sarah', 'dedicated', 'student', 'passion', 'mathematics', 'physic', 'interest'], 'Alex': ['science', 'alex', 'tech', 'enthusiast', 'studying', 'computer', 'data'], 'Emily': ['creative', 'emily', 'avid', 'reader', 'historian', 'focusing', 'literature'], 'James': ['james', 'science', 'enthusiast', 'excelling', 'biology', 'chemistry', 'interest'], 'Mia': ['mia', 'student', 'economics', 'political', 'science', 'passionate', 'understanding'], 'Ryan': ['ryan', 'aspiring', 'engineer', 'fascinated', 'robotics', 'renewable', 'energy'], 'Sophia': ['sophia', 'dedicated', 'student', 'focusing', 'sociology', 'gender', 'study'], 'Lucas': ['art', 'lucas', 'enthusiast', 'studying', 'fine', 'sculpture', 'interest'], 'Ethan ': ['genetic', 'engineering', 'biotechnology', 'ethan', 'academic', 'journey', 'biology'], 'Olivia': ['environmental', 'olivia', 'budding', 'scientist', 'specializing', 'science', 'geology'], 'Lily': ['chemistry', 'environmental', 'lily', 'dedicated', 'student', 'focusing', 'science'], 'Max': ['ethical', 'hacking', 'max', 'aspiring', 'computer', 'engineering', 'student'], 'Ava': ['study', 'ava', 'delf', 'world', 'language', 'culture', 'linguistics'], 'Noah': ['financial', 'market', 'noah', 'academic', 'focus', 'economics', 'finance'], 'Zoe': ['international', 'diplomacy', 'global', 'zoe', 'immerses', 'political', 'science'], 'Leo': ['leo', 'explores', 'wonder', 'universe', 'study', 'physic', 'astronomy'], 'Harper': ['psychology', 'behavioral', 'economics', 'harper', 'delf', 'realm', 'exploring'], 'Mason': ['mechanical', 'robotics', 'automation', 'mason', 'pursuit', 'engineering', 'reflect'], 'Amelia': ['art', 'amelia', 'delf', 'world', 'study', 'history', 'fine'], 'Oliver': ['software', 'oliver', 'aspiring', 'tech', 'enthusiast', 'studying', 'computer'], 'Isabella': ['marine', 'isabella', 'delf', 'world', 'environmental', 'science', 'biology'], 'William': ['history', 'ancient', 'william', 'enthusiast', 'exploring', 'realm', 'archaeology'], 'Grace': ['health', 'disease', 'grace', 'focus', 'public', 'epidemiology', 'passion'], 'Benjamin': ['engineering', 'aerospace', 'space', 'exploration', 'benjamin', 'academic', 'pursuit'], 'Gia': ['human', 'right', 'advocating', 'gia', 'delf', 'political', 'science'], 'Henry': ['financial', 'market', 'risk', 'henry', 'academic', 'focus', 'finance'], 'Charlotte': ['creative', 'writing', 'charlotte', 'immerses', 'world', 'literature', 'passion']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# This defaultdict will store counts and names for each tag\n",
        "tag_to_overall_count_and_names = defaultdict(lambda: {\"count\": 0, \"names\": defaultdict(int)})\n",
        "\n",
        "for name, tags in name_to_top_tags.items():\n",
        "    for tag in tags:\n",
        "        # Increase the overall count for the tag\n",
        "        tag_to_overall_count_and_names[tag][\"count\"] += 1\n",
        "        # Increase the count for this tag under this specific name\n",
        "        tag_to_overall_count_and_names[tag][\"names\"][name] += 1\n",
        "\n",
        "# Now, printing results as per your format:\n",
        "for tag, info in tag_to_overall_count_and_names.items():\n",
        "    names_counts = ', '.join([f\"{name} - {count}\" for name, count in info[\"names\"].items()])\n",
        "    print(f\"{tag.capitalize()} - {names_counts}; Total - {info['count']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM8-6Dh2OOqD",
        "outputId": "29fc797a-2876-46c9-d6bd-e3ced663cdf6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sarah - Sarah - 1; Total - 1\n",
            "Dedicated - Sarah - 1, Sophia - 1, Lily - 1; Total - 3\n",
            "Student - Sarah - 1, Mia - 1, Sophia - 1, Lily - 1, Max - 1; Total - 5\n",
            "Passion - Sarah - 1, Grace - 1, Charlotte - 1; Total - 3\n",
            "Mathematics - Sarah - 1; Total - 1\n",
            "Physic - Sarah - 1, Leo - 1; Total - 2\n",
            "Interest - Sarah - 1, James - 1, Lucas - 1; Total - 3\n",
            "Science - Alex - 1, James - 1, Mia - 1, Olivia - 1, Lily - 1, Zoe - 1, Isabella - 1, Gia - 1; Total - 8\n",
            "Alex - Alex - 1; Total - 1\n",
            "Tech - Alex - 1, Oliver - 1; Total - 2\n",
            "Enthusiast - Alex - 1, James - 1, Lucas - 1, Oliver - 1, William - 1; Total - 5\n",
            "Studying - Alex - 1, Lucas - 1, Oliver - 1; Total - 3\n",
            "Computer - Alex - 1, Max - 1, Oliver - 1; Total - 3\n",
            "Data - Alex - 1; Total - 1\n",
            "Creative - Emily - 1, Charlotte - 1; Total - 2\n",
            "Emily - Emily - 1; Total - 1\n",
            "Avid - Emily - 1; Total - 1\n",
            "Reader - Emily - 1; Total - 1\n",
            "Historian - Emily - 1; Total - 1\n",
            "Focusing - Emily - 1, Sophia - 1, Lily - 1; Total - 3\n",
            "Literature - Emily - 1, Charlotte - 1; Total - 2\n",
            "James - James - 1; Total - 1\n",
            "Excelling - James - 1; Total - 1\n",
            "Biology - James - 1, Ethan  - 1, Isabella - 1; Total - 3\n",
            "Chemistry - James - 1, Lily - 1; Total - 2\n",
            "Mia - Mia - 1; Total - 1\n",
            "Economics - Mia - 1, Noah - 1, Harper - 1; Total - 3\n",
            "Political - Mia - 1, Zoe - 1, Gia - 1; Total - 3\n",
            "Passionate - Mia - 1; Total - 1\n",
            "Understanding - Mia - 1; Total - 1\n",
            "Ryan - Ryan - 1; Total - 1\n",
            "Aspiring - Ryan - 1, Max - 1, Oliver - 1; Total - 3\n",
            "Engineer - Ryan - 1; Total - 1\n",
            "Fascinated - Ryan - 1; Total - 1\n",
            "Robotics - Ryan - 1, Mason - 1; Total - 2\n",
            "Renewable - Ryan - 1; Total - 1\n",
            "Energy - Ryan - 1; Total - 1\n",
            "Sophia - Sophia - 1; Total - 1\n",
            "Sociology - Sophia - 1; Total - 1\n",
            "Gender - Sophia - 1; Total - 1\n",
            "Study - Sophia - 1, Ava - 1, Leo - 1, Amelia - 1; Total - 4\n",
            "Art - Lucas - 1, Amelia - 1; Total - 2\n",
            "Lucas - Lucas - 1; Total - 1\n",
            "Fine - Lucas - 1, Amelia - 1; Total - 2\n",
            "Sculpture - Lucas - 1; Total - 1\n",
            "Genetic - Ethan  - 1; Total - 1\n",
            "Engineering - Ethan  - 1, Max - 1, Mason - 1, Benjamin - 1; Total - 4\n",
            "Biotechnology - Ethan  - 1; Total - 1\n",
            "Ethans - Ethan  - 1; Total - 1\n",
            "Academic - Ethan  - 1, Noah - 1, Benjamin - 1, Henry - 1; Total - 4\n",
            "Journey - Ethan  - 1; Total - 1\n",
            "Environmental - Olivia - 1, Lily - 1, Isabella - 1; Total - 3\n",
            "Olivia - Olivia - 1; Total - 1\n",
            "Budding - Olivia - 1; Total - 1\n",
            "Scientist - Olivia - 1; Total - 1\n",
            "Specializing - Olivia - 1; Total - 1\n",
            "Geology - Olivia - 1; Total - 1\n",
            "Lily - Lily - 1; Total - 1\n",
            "Ethical - Max - 1; Total - 1\n",
            "Hacking - Max - 1; Total - 1\n",
            "Max - Max - 1; Total - 1\n",
            "Ava - Ava - 1; Total - 1\n",
            "Delf - Ava - 1, Harper - 1, Amelia - 1, Isabella - 1, Gia - 1; Total - 5\n",
            "World - Ava - 1, Amelia - 1, Isabella - 1, Charlotte - 1; Total - 4\n",
            "Language - Ava - 1; Total - 1\n",
            "Culture - Ava - 1; Total - 1\n",
            "Linguistics - Ava - 1; Total - 1\n",
            "Financial - Noah - 1, Henry - 1; Total - 2\n",
            "Market - Noah - 1, Henry - 1; Total - 2\n",
            "Noah - Noah - 1; Total - 1\n",
            "Focus - Noah - 1, Grace - 1, Henry - 1; Total - 3\n",
            "Finance - Noah - 1, Henry - 1; Total - 2\n",
            "International - Zoe - 1; Total - 1\n",
            "Diplomacy - Zoe - 1; Total - 1\n",
            "Global - Zoe - 1; Total - 1\n",
            "Zoe - Zoe - 1; Total - 1\n",
            "Immerses - Zoe - 1, Charlotte - 1; Total - 2\n",
            "Leo - Leo - 1; Total - 1\n",
            "Explores - Leo - 1; Total - 1\n",
            "Wonder - Leo - 1; Total - 1\n",
            "Universe - Leo - 1; Total - 1\n",
            "Astronomy - Leo - 1; Total - 1\n",
            "Psychology - Harper - 1; Total - 1\n",
            "Behavioral - Harper - 1; Total - 1\n",
            "Harper - Harper - 1; Total - 1\n",
            "Realm - Harper - 1, William - 1; Total - 2\n",
            "Exploring - Harper - 1, William - 1; Total - 2\n",
            "Mechanical - Mason - 1; Total - 1\n",
            "Automation - Mason - 1; Total - 1\n",
            "Mason - Mason - 1; Total - 1\n",
            "Pursuit - Mason - 1, Benjamin - 1; Total - 2\n",
            "Reflect - Mason - 1; Total - 1\n",
            "Amelia - Amelia - 1; Total - 1\n",
            "History - Amelia - 1, William - 1; Total - 2\n",
            "Software - Oliver - 1; Total - 1\n",
            "Oliver - Oliver - 1; Total - 1\n",
            "Marine - Isabella - 1; Total - 1\n",
            "Isabella - Isabella - 1; Total - 1\n",
            "Ancient - William - 1; Total - 1\n",
            "William - William - 1; Total - 1\n",
            "Archaeology - William - 1; Total - 1\n",
            "Health - Grace - 1; Total - 1\n",
            "Disease - Grace - 1; Total - 1\n",
            "Grace - Grace - 1; Total - 1\n",
            "Public - Grace - 1; Total - 1\n",
            "Epidemiology - Grace - 1; Total - 1\n",
            "Aerospace - Benjamin - 1; Total - 1\n",
            "Space - Benjamin - 1; Total - 1\n",
            "Exploration - Benjamin - 1; Total - 1\n",
            "Benjamin - Benjamin - 1; Total - 1\n",
            "Human - Gia - 1; Total - 1\n",
            "Right - Gia - 1; Total - 1\n",
            "Advocating - Gia - 1; Total - 1\n",
            "Gia - Gia - 1; Total - 1\n",
            "Risk - Henry - 1; Total - 1\n",
            "Henry - Henry - 1; Total - 1\n",
            "Writing - Charlotte - 1; Total - 1\n",
            "Charlotte - Charlotte - 1; Total - 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# Assuming data is loaded into a DataFrame `data`\n",
        "data = pd.read_csv(\"/content/Final_pd.csv\")\n",
        "\n",
        "# Custom stopwords\n",
        "custom_stopwords = {'dedicated', 'life', 'passion', 'interest'}  # Extend as needed\n",
        "stop_words = set(stopwords.words('english')).union(custom_stopwords)\n",
        "\n",
        "# Function to tokenize, remove custom stopwords and verbs\n",
        "def tokenize_and_filter(text):\n",
        "    tokens = word_tokenize(text.lower())  # Tokenize and lower case\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]  # Remove custom stopwords\n",
        "    # POS tagging and filter out verbs (keep nouns, NN; you might also keep adjectives, JJ)\n",
        "    tagged = pos_tag(filtered_tokens)\n",
        "    nouns_adjectives = [word for word, tag in tagged if tag.startswith('NN') or tag.startswith('JJ')]\n",
        "    return ' '.join(nouns_adjectives)\n",
        "\n",
        "# Apply the function to the descriptions\n",
        "data['filtered_description'] = data['Description'].apply(tokenize_and_filter)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit TF-IDF on the filtered descriptions\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['filtered_description'])\n",
        "\n",
        "# Extract feature names to map back to words\n",
        "features = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "### Step 3: Extracting Top 7 Tags\n",
        "\n",
        "def get_top_n_tags(row_data, features, n=7):\n",
        "    # Get indices sorted by value in descending order\n",
        "    sorted_indices = row_data.argsort()[-n:][::-1]\n",
        "    return [features[i] for i in sorted_indices]\n",
        "\n",
        "# Extract top 7 tags for each row\n",
        "data['Top_7_Tags'] = [get_top_n_tags(row, features) for row in tfidf_matrix.toarray()]\n",
        "\n",
        "### Step 4: Map Names to Tags and Count\n",
        "\n",
        "name_to_top_tags = pd.Series(data['Top_7_Tags'].values, index=data['Name']).to_dict()\n",
        "\n",
        "print(name_to_top_tags)\n",
        "\n",
        "tag_to_names = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "# Populate tag_to_names\n",
        "for name, tags in name_to_top_tags.items():\n",
        "    for tag in tags:\n",
        "        tag_to_names[tag][name] += 1\n",
        "\n",
        "# Consolidate counts and print\n",
        "for tag, names in tag_to_names.items():\n",
        "    count = sum(names.values())  # Total count for the tag\n",
        "    names_str = ', '.join([f\"{name} {names[name]}\" for name in names])\n",
        "    print(f\"{tag.capitalize()} - {names_str}; Total: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDn1uc3nPKds",
        "outputId": "0c13b8ba-7850-4cda-abd6-4b1d69341dfa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Sarah': ['astrophysics', 'quantum', 'mechanics', 'curiosity', 'fervor', 'sarah', 'mathematics'], 'Alex': ['science', 'machine', 'learning', 'data', 'computing', 'intelligence', 'alex'], 'Emily': ['creative', 'deep', 'historian', 'avid', 'joy', 'narratives', 'reader'], 'James': ['experiments', 'molecular', 'unravel', 'james', 'level', 'chemistry', 'genetics'], 'Mia': ['policy', 'mia', 'positive', 'commitment', 'impact', 'society', 'passionate'], 'Ryan': ['projects', 'engineer', 'autonomous', 'friendly', 'renewable', 'eco', 'energy'], 'Sophia': ['structures', 'gender', 'intersectionality', 'equality', 'social', 'societal', 'sociology'], 'Lucas': ['art', 'explores', 'traditional', 'installation', 'sculpture', 'boundaries', 'inspire'], 'Ethan ': ['genetic', 'biotechnology', 'engineering', 'applications', 'manipulation', 'advancements', 'realm'], 'Olivia': ['environmental', 'scientist', 'natural', 'earth', 'propel', 'generations', 'geology'], 'Lily': ['chemistry', 'environmental', 'knowledge', 'challenges', 'address', 'sustainability', 'mitigation'], 'Max': ['ethical', 'hacking', 'secure', 'network', 'keen', 'max', 'contribute'], 'Ava': ['studies', 'ava', 'gaps', 'linguistic', 'bridge', 'communication', 'multilingualism'], 'Noah': ['financial', 'planning', 'precision', 'noah', 'economic', 'analysis', 'stock'], 'Zoe': ['international', 'global', 'zoe', 'affairs', 'cooperation', 'aspirations', 'governance'], 'Leo': ['objects', 'wonders', 'beauty', 'cosmology', 'inquiry', 'leo', 'astrophotography'], 'Harper': ['behavioral', 'psychology', 'economics', 'understand', 'harper', 'processes', 'cognitive'], 'Mason': ['mechanical', 'robotics', 'efficiency', 'mason', 'biomechanics', 'functionality', 'automation'], 'Amelia': ['art', 'media', 'mixed', 'modern', 'techniques', 'creativity', 'amelia'], 'Oliver': ['software', 'development', 'cybersecurity', 'tech', 'digital', 'security', 'solutions'], 'Isabella': ['marine', 'intricate', 'oceanography', 'conservation', 'isabella', 'dynamics', 'biology'], 'William': ['ancient', 'history', 'cultures', 'preservation', 'past', 'stories', 'archaeology'], 'Grace': ['health', 'dedication', 'diseases', 'worldwide', 'epidemiology', 'initiatives', 'prevention'], 'Benjamin': ['engineering', 'space', 'exploration', 'travel', 'aerodynamics', 'aerospace', 'benjamin'], 'Gia': ['rights', 'human', 'gia', 'scale', 'frameworks', 'legal', 'law'], 'Henry': ['financial', 'navigates', 'acumen', 'strategic', 'management', 'banking', 'henry'], 'Charlotte': ['creative', 'imagination', 'fiction', 'poetry', 'charlotte', 'words', 'literary']}\n",
            "Astrophysics - Sarah 1; Total: 1\n",
            "Quantum - Sarah 1; Total: 1\n",
            "Mechanics - Sarah 1; Total: 1\n",
            "Curiosity - Sarah 1; Total: 1\n",
            "Fervor - Sarah 1; Total: 1\n",
            "Sarah - Sarah 1; Total: 1\n",
            "Mathematics - Sarah 1; Total: 1\n",
            "Science - Alex 1; Total: 1\n",
            "Machine - Alex 1; Total: 1\n",
            "Learning - Alex 1; Total: 1\n",
            "Data - Alex 1; Total: 1\n",
            "Computing - Alex 1; Total: 1\n",
            "Intelligence - Alex 1; Total: 1\n",
            "Alex - Alex 1; Total: 1\n",
            "Creative - Emily 1, Charlotte 1; Total: 2\n",
            "Deep - Emily 1; Total: 1\n",
            "Historian - Emily 1; Total: 1\n",
            "Avid - Emily 1; Total: 1\n",
            "Joy - Emily 1; Total: 1\n",
            "Narratives - Emily 1; Total: 1\n",
            "Reader - Emily 1; Total: 1\n",
            "Experiments - James 1; Total: 1\n",
            "Molecular - James 1; Total: 1\n",
            "Unravel - James 1; Total: 1\n",
            "James - James 1; Total: 1\n",
            "Level - James 1; Total: 1\n",
            "Chemistry - James 1, Lily 1; Total: 2\n",
            "Genetics - James 1; Total: 1\n",
            "Policy - Mia 1; Total: 1\n",
            "Mia - Mia 1; Total: 1\n",
            "Positive - Mia 1; Total: 1\n",
            "Commitment - Mia 1; Total: 1\n",
            "Impact - Mia 1; Total: 1\n",
            "Society - Mia 1; Total: 1\n",
            "Passionate - Mia 1; Total: 1\n",
            "Projects - Ryan 1; Total: 1\n",
            "Engineer - Ryan 1; Total: 1\n",
            "Autonomous - Ryan 1; Total: 1\n",
            "Friendly - Ryan 1; Total: 1\n",
            "Renewable - Ryan 1; Total: 1\n",
            "Eco - Ryan 1; Total: 1\n",
            "Energy - Ryan 1; Total: 1\n",
            "Structures - Sophia 1; Total: 1\n",
            "Gender - Sophia 1; Total: 1\n",
            "Intersectionality - Sophia 1; Total: 1\n",
            "Equality - Sophia 1; Total: 1\n",
            "Social - Sophia 1; Total: 1\n",
            "Societal - Sophia 1; Total: 1\n",
            "Sociology - Sophia 1; Total: 1\n",
            "Art - Lucas 1, Amelia 1; Total: 2\n",
            "Explores - Lucas 1; Total: 1\n",
            "Traditional - Lucas 1; Total: 1\n",
            "Installation - Lucas 1; Total: 1\n",
            "Sculpture - Lucas 1; Total: 1\n",
            "Boundaries - Lucas 1; Total: 1\n",
            "Inspire - Lucas 1; Total: 1\n",
            "Genetic - Ethan  1; Total: 1\n",
            "Biotechnology - Ethan  1; Total: 1\n",
            "Engineering - Ethan  1, Benjamin 1; Total: 2\n",
            "Applications - Ethan  1; Total: 1\n",
            "Manipulation - Ethan  1; Total: 1\n",
            "Advancements - Ethan  1; Total: 1\n",
            "Realm - Ethan  1; Total: 1\n",
            "Environmental - Olivia 1, Lily 1; Total: 2\n",
            "Scientist - Olivia 1; Total: 1\n",
            "Natural - Olivia 1; Total: 1\n",
            "Earth - Olivia 1; Total: 1\n",
            "Propel - Olivia 1; Total: 1\n",
            "Generations - Olivia 1; Total: 1\n",
            "Geology - Olivia 1; Total: 1\n",
            "Knowledge - Lily 1; Total: 1\n",
            "Challenges - Lily 1; Total: 1\n",
            "Address - Lily 1; Total: 1\n",
            "Sustainability - Lily 1; Total: 1\n",
            "Mitigation - Lily 1; Total: 1\n",
            "Ethical - Max 1; Total: 1\n",
            "Hacking - Max 1; Total: 1\n",
            "Secure - Max 1; Total: 1\n",
            "Network - Max 1; Total: 1\n",
            "Keen - Max 1; Total: 1\n",
            "Max - Max 1; Total: 1\n",
            "Contribute - Max 1; Total: 1\n",
            "Studies - Ava 1; Total: 1\n",
            "Ava - Ava 1; Total: 1\n",
            "Gaps - Ava 1; Total: 1\n",
            "Linguistic - Ava 1; Total: 1\n",
            "Bridge - Ava 1; Total: 1\n",
            "Communication - Ava 1; Total: 1\n",
            "Multilingualism - Ava 1; Total: 1\n",
            "Financial - Noah 1, Henry 1; Total: 2\n",
            "Planning - Noah 1; Total: 1\n",
            "Precision - Noah 1; Total: 1\n",
            "Noah - Noah 1; Total: 1\n",
            "Economic - Noah 1; Total: 1\n",
            "Analysis - Noah 1; Total: 1\n",
            "Stock - Noah 1; Total: 1\n",
            "International - Zoe 1; Total: 1\n",
            "Global - Zoe 1; Total: 1\n",
            "Zoe - Zoe 1; Total: 1\n",
            "Affairs - Zoe 1; Total: 1\n",
            "Cooperation - Zoe 1; Total: 1\n",
            "Aspirations - Zoe 1; Total: 1\n",
            "Governance - Zoe 1; Total: 1\n",
            "Objects - Leo 1; Total: 1\n",
            "Wonders - Leo 1; Total: 1\n",
            "Beauty - Leo 1; Total: 1\n",
            "Cosmology - Leo 1; Total: 1\n",
            "Inquiry - Leo 1; Total: 1\n",
            "Leo - Leo 1; Total: 1\n",
            "Astrophotography - Leo 1; Total: 1\n",
            "Behavioral - Harper 1; Total: 1\n",
            "Psychology - Harper 1; Total: 1\n",
            "Economics - Harper 1; Total: 1\n",
            "Understand - Harper 1; Total: 1\n",
            "Harper - Harper 1; Total: 1\n",
            "Processes - Harper 1; Total: 1\n",
            "Cognitive - Harper 1; Total: 1\n",
            "Mechanical - Mason 1; Total: 1\n",
            "Robotics - Mason 1; Total: 1\n",
            "Efficiency - Mason 1; Total: 1\n",
            "Mason - Mason 1; Total: 1\n",
            "Biomechanics - Mason 1; Total: 1\n",
            "Functionality - Mason 1; Total: 1\n",
            "Automation - Mason 1; Total: 1\n",
            "Media - Amelia 1; Total: 1\n",
            "Mixed - Amelia 1; Total: 1\n",
            "Modern - Amelia 1; Total: 1\n",
            "Techniques - Amelia 1; Total: 1\n",
            "Creativity - Amelia 1; Total: 1\n",
            "Amelia - Amelia 1; Total: 1\n",
            "Software - Oliver 1; Total: 1\n",
            "Development - Oliver 1; Total: 1\n",
            "Cybersecurity - Oliver 1; Total: 1\n",
            "Tech - Oliver 1; Total: 1\n",
            "Digital - Oliver 1; Total: 1\n",
            "Security - Oliver 1; Total: 1\n",
            "Solutions - Oliver 1; Total: 1\n",
            "Marine - Isabella 1; Total: 1\n",
            "Intricate - Isabella 1; Total: 1\n",
            "Oceanography - Isabella 1; Total: 1\n",
            "Conservation - Isabella 1; Total: 1\n",
            "Isabella - Isabella 1; Total: 1\n",
            "Dynamics - Isabella 1; Total: 1\n",
            "Biology - Isabella 1; Total: 1\n",
            "Ancient - William 1; Total: 1\n",
            "History - William 1; Total: 1\n",
            "Cultures - William 1; Total: 1\n",
            "Preservation - William 1; Total: 1\n",
            "Past - William 1; Total: 1\n",
            "Stories - William 1; Total: 1\n",
            "Archaeology - William 1; Total: 1\n",
            "Health - Grace 1; Total: 1\n",
            "Dedication - Grace 1; Total: 1\n",
            "Diseases - Grace 1; Total: 1\n",
            "Worldwide - Grace 1; Total: 1\n",
            "Epidemiology - Grace 1; Total: 1\n",
            "Initiatives - Grace 1; Total: 1\n",
            "Prevention - Grace 1; Total: 1\n",
            "Space - Benjamin 1; Total: 1\n",
            "Exploration - Benjamin 1; Total: 1\n",
            "Travel - Benjamin 1; Total: 1\n",
            "Aerodynamics - Benjamin 1; Total: 1\n",
            "Aerospace - Benjamin 1; Total: 1\n",
            "Benjamin - Benjamin 1; Total: 1\n",
            "Rights - Gia 1; Total: 1\n",
            "Human - Gia 1; Total: 1\n",
            "Gia - Gia 1; Total: 1\n",
            "Scale - Gia 1; Total: 1\n",
            "Frameworks - Gia 1; Total: 1\n",
            "Legal - Gia 1; Total: 1\n",
            "Law - Gia 1; Total: 1\n",
            "Navigates - Henry 1; Total: 1\n",
            "Acumen - Henry 1; Total: 1\n",
            "Strategic - Henry 1; Total: 1\n",
            "Management - Henry 1; Total: 1\n",
            "Banking - Henry 1; Total: 1\n",
            "Henry - Henry 1; Total: 1\n",
            "Imagination - Charlotte 1; Total: 1\n",
            "Fiction - Charlotte 1; Total: 1\n",
            "Poetry - Charlotte 1; Total: 1\n",
            "Charlotte - Charlotte 1; Total: 1\n",
            "Words - Charlotte 1; Total: 1\n",
            "Literary - Charlotte 1; Total: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZPILd2UBWbwL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}